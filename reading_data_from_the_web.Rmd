---
title: "reading_data_from_the_web"
author: "Emily Potts"
date: "2022-10-13"
output: github_document
---


```{r setup, include=FALSE}
library(tidyverse)
library(rvest)
library(httr)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

```{r}
library(tidyverse)
library(rvest)
library(httr)
```


# Extracting data
```{r}
url = "http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm"
drug_use_html = read_html(url)

drug_use_html
```

all the tables
```{r}
drug_use_html %>% 
  html_table()
```

just the first table
```{r}
table_marj =
  drug_use_html %>% 
  html_table() %>% 
  first()
```

```{r}
table_marj =
  drug_use_html %>% 
  html_table() %>% 
  first() %>% 
  slice(-1)

table_marj
```


# CSS selectors

```{r}
swm_html = 
  read_html("https://www.imdb.com/list/ls070150896/")
```

how do i get the stuff i want?
```{r}
sw_titles =
  swm_html %>% 
  html_elements(".lister-item-header a") %>% 
  html_text()

sw_runtime =
  swm_html %>% 
  html_elements(".runtime") %>% 
  html_text()

sw_runtime

sw_money =
  swm_html %>% 
  html_elements(".text-small:nth-child(7) span:nth-child(5)") %>% 
  html_text()
sw_money
```

```{r}
sw_df = 
  tibble(
    title = sw_titles,
    runtime = sw_runtime, 
    money = sw_money
  )
sw_df
```


example w napoleon dynamite
```{r}
url = "https://www.amazon.com/product-reviews/B00005JNBQ/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=avp_only_reviews&sortBy=recent&pageNumber=1"

dynamite_html = read_html(url)

review_titles = 
  dynamite_html %>%
  html_elements(".a-text-bold span") %>%
  html_text()

review_stars = 
  dynamite_html %>%
  html_elements("#cm_cr-review_list .review-rating") %>%
  html_text()

review_text = 
  dynamite_html %>%
  html_elements(".review-text-content span") %>%
  html_text()

reviews = tibble(
  title = review_titles,
  stars = review_stars,
  text = review_text
)

reviews
```



# Using an API

nyc open data

as a csv file
```{r}
nyc_water = 
  GET("https://data.cityofnewyork.us/resource/ia2d-e54m.csv") %>% 
  content("parsed")
nyc_water
```

as a JSON file
```{r}
nyc_water = 
  GET("https://data.cityofnewyork.us/resource/ia2d-e54m.json") %>% 
  content("text") %>%
  jsonlite::fromJSON() %>%
  as_tibble()
nyc_water
```

data.gov
```{r}
brfss_smart2010 = 
  GET("https://chronicdata.cdc.gov/resource/acme-vg9e.csv",
      query = list("$limit" = 5000)) %>% 
  content("parsed")
brfss_smart2010
```
By default, the CDC API limits data to the first 1000 rows. Here I’ve increased that by changing an element of the API query – I looked around the website describing the API to find the name of the argument, and then used the appropriate syntax for GET. To get the full data, I could increase this so that I get all the data at once or I could try iterating over chunks of a few thousand rows.

pokemon api (more complicated)
```{r}
poke = 
  GET("http://pokeapi.co/api/v2/pokemon/1") %>%
  content()
poke
names(poke)
poke[["weight"]]
```


